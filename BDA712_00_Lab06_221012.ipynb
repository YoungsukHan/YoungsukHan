{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Session \\# 06\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "by Josué Obregón <br>\n",
        "BDA712-00 - Machine Learning Programming <br>\n",
        "Department of Big Data Analytics - Kyung Hee University<br>\n",
        "\n",
        "## Objective\n",
        "\n",
        "The objective of this session is to try our logistic regression implementation using more complex data and to implement multiple class classification. \n"
      ],
      "metadata": {
        "id": "jCqG2Vz70NNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the data"
      ],
      "metadata": {
        "id": "tffQN5TXQoMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown"
      ],
      "metadata": {
        "id": "2M5n_qs5acMe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "vouLYEd0aZcf",
        "outputId": "dfaffb2f-5c11-4e9c-ca39-3f56922cfc95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls = ['https://drive.google.com/uc?export=download&id=1MnUH3W1Jm8LVBqEJ1M0m5l9_Q8hJZqrz', # train-labels-idx1-ubyte.gz  https://drive.google.com/file/d/1MnUH3W1Jm8LVBqEJ1M0m5l9_Q8hJZqrz/view?usp=sharing       \n",
        "        'https://drive.google.com/uc?export=download&id=1AZLWnMx1xe3vN1naEswKL19I02YrA7_J', # train-images-idx3-ubyte.gz  https://drive.google.com/file/d/1AZLWnMx1xe3vN1naEswKL19I02YrA7_J/view?usp=sharing       \n",
        "        'https://drive.google.com/uc?export=download&id=1Hw8QHRxmI4w-ZAo5yzVjDB3UnUPAVv4u', # t10k-labels-idx1-ubyte.gz  https://drive.google.com/file/d/1Hw8QHRxmI4w-ZAo5yzVjDB3UnUPAVv4u/view?usp=sharing       \n",
        "        'https://drive.google.com/uc?export=download&id=1EHdJfVQs1ZiRhCoEldMc9lTJ-5Nz5GaV', # t10k-images-idx3-ubyte.gz  https://drive.google.com/file/d/1EHdJfVQs1ZiRhCoEldMc9lTJ-5Nz5GaV/view?usp=sharing       \n",
        "      ]\n",
        "outputs = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
        "           't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n",
        "for url,output in zip(urls,outputs):\n",
        "  gdown.download(url, f'data/{output}', quiet=False)"
      ],
      "metadata": {
        "id": "gkFTKhLl0I72",
        "outputId": "20c751e4-cb22-4bf4-8d45-6a431b670259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1MnUH3W1Jm8LVBqEJ1M0m5l9_Q8hJZqrz\n",
            "To: /content/data/train-labels-idx1-ubyte.gz\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 54.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1AZLWnMx1xe3vN1naEswKL19I02YrA7_J\n",
            "To: /content/data/train-images-idx3-ubyte.gz\n",
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 253MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1Hw8QHRxmI4w-ZAo5yzVjDB3UnUPAVv4u\n",
            "To: /content/data/t10k-labels-idx1-ubyte.gz\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.83MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1EHdJfVQs1ZiRhCoEldMc9lTJ-5Nz5GaV\n",
            "To: /content/data/t10k-images-idx3-ubyte.gz\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 218MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries\n",
        "\n",
        "Let's import the data and prepare the variables that we will need for our laboratory"
      ],
      "metadata": {
        "id": "zhc1fdmralXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "import struct\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "ElL0PnEca2tJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "import struct\n",
        "\n",
        "\n",
        "def load_images(filename):\n",
        "    # Open and unzip the file of images:\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        # Read the header information into a bunch of variables\n",
        "        _ignored, n_images, columns, rows = struct.unpack('>IIII', f.read(16))\n",
        "        # Read all the pixels into a NumPy array of bytes:\n",
        "        all_pixels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        # Reshape the pixels into a matrix where each line is an image:\n",
        "        return all_pixels.reshape(n_images, columns * rows)\n",
        "\n",
        "\n",
        "def prepend_bias(X):\n",
        "    # Insert a column of 1s in the position 0 of X.\n",
        "    # (“axis=1” stands for: “insert a column, not a row”)\n",
        "  return np.insert(X, 0, 1, axis=1) # insert(arr, obj, values, axis=None)"
      ],
      "metadata": {
        "id": "RScsBDxmm7id"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 60000 images, each 785 elements (1 bias + 28 * 28 pixels)\n",
        "X_train = prepend_bias(load_images('data/train-images-idx3-ubyte.gz'))\n",
        "\n",
        "# 10000 images, each 785 elements, with the same structure as X_train\n",
        "X_test = prepend_bias(load_images('data/t10k-images-idx3-ubyte.gz'))"
      ],
      "metadata": {
        "id": "hv3YmTIzn6mg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring MNIST data"
      ],
      "metadata": {
        "id": "PvMQ5i48sMyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explore the variables we just created"
      ],
      "metadata": {
        "id": "uOS90jBHocL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "WdoCScaUobUF",
        "outputId": "5d834162-e90c-4983-e946-b30a2a9412cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "pACbt7C0oLKO",
        "outputId": "60c664f4-1ce8-42ad-e7ff-5b96417127aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's observe the data we loaded"
      ],
      "metadata": {
        "id": "MoXc-qzgony_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_id_train = 30\n",
        "sample_train_image = X_train\n",
        "image = np.reshape(sample_train_image[sample_id_train, 1:], (28, 28))\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "ckSrcWkNonT9",
        "outputId": "a4cf7f5c-7a7a-488c-f306-2ebc7ffd8885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8931db4550>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sZ7XA6OqCDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q8bos4rwomyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the labels now. Run the following code"
      ],
      "metadata": {
        "id": "wcWq4ajCcFcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(filename):\n",
        "    # Open and unzip the file of images:\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        # Skip the header bytes:\n",
        "        f.read(8)\n",
        "        # Read all the labels into a list:\n",
        "        all_labels = f.read()\n",
        "        # Reshape the list of labels into a one-column matrix:\n",
        "        return np.frombuffer(all_labels, dtype=np.uint8).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "8a_8L04kcEb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the function to load the labels for train and test data. Then let's explore the variables we just created."
      ],
      "metadata": {
        "id": "LXBNra2kqmnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 60K labels, each with value 1 if the digit is a five, and 0 otherwise\n",
        "Y_train = load_labels('data/train-labels-idx1-ubyte.gz')\n",
        "\n",
        "# 10000 labels, with the same encoding as Y_train\n",
        "Y_test = load_labels('data/t10k-labels-idx1-ubyte.gz')"
      ],
      "metadata": {
        "id": "qV8zMregqcAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kr5z7s4urCvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJczwlAerCyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MVCXGIB4rC0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary classification (using only one number)\n",
        "\n",
        "The matrix returned by `load_labels()` contains labels from 0 to 9. But let's start simple and do binary classificatino first. You can choose any number you like. I will use number 5 but you can change that.\n",
        "\n",
        "Let's first define a way to transform our multiclass classification problem into a binary classification problem."
      ],
      "metadata": {
        "id": "czahv9KesRNU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QI9J9aplvUaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3Lcm0pNvZI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhDIHk6evgBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3eHgAOQ0sQac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DnyIJIDhsQRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lm2KfmyHsP8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_aTcGw49v9mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load all the functions we created in the last notebook"
      ],
      "metadata": {
        "id": "hcFBzJWlyxrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1/ (1+np.exp(-z))\n",
        "\n",
        "\n",
        "def gradient(X, Y, beta):\n",
        "  return np.matmul(X.T, (forward(X, beta) - Y)) / X.shape[0]\n",
        "\n",
        "\n",
        "def forward(X, beta):\n",
        "  weighted_sum = np.matmul(X, beta)\n",
        "  return sigmoid(weighted_sum)\n",
        "\n",
        "def predict(X, beta, return_proba=False):\n",
        "  if return_proba:\n",
        "    return forward(X,beta)\n",
        "  else:\n",
        "    return np.round(forward(X,beta))\n",
        "\n",
        "def log_loss(X, Y, beta):\n",
        "    y_hat = forward(X,beta)\n",
        "    first_term = Y * np.log(y_hat)\n",
        "    second_term = (1 - Y) * np.log(1 - y_hat)\n",
        "    return -np.sum(first_term + second_term) / X.shape[0]\n",
        "\n",
        "def train(X, Y, iterations, lr=0.001, precision=1e-6, print_step=1):\n",
        "  beta = np.zeros((X.shape[1], 1))\n",
        "  previous_loss = log_loss(X, Y, beta) \n",
        "  for i in range(iterations):\n",
        "    if i % print_step ==0:\n",
        "      print(f'Iteration {i} => Loss(MSE): {previous_loss:.10f}')\n",
        "    beta -= gradient(X, Y, beta) * lr\n",
        "\n",
        "    current_loss = log_loss(X, Y, beta)\n",
        "    if (abs(current_loss - previous_loss) < precision):\n",
        "      print(f'Early stop at iteration {i}')\n",
        "      return beta\n",
        "    previous_loss = current_loss\n",
        "\n",
        "  return beta\n",
        "\n",
        "def test(X,Y, beta):\n",
        "  n = X.shape[0]\n",
        "  tp = np.sum(predict(X, beta) == Y) # correct results\n",
        "  accuracy = (tp / n) * 100 # success percent\n",
        "  print(f'\\nSuccess: {tp}/{n} ({accuracy:.2f})%')"
      ],
      "metadata": {
        "id": "BbHsxZwTyxGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ak1J3t0K0awj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F-JYRZ0X3y_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oCqVXkm83q0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary first part\n",
        "\n",
        "In this part of the session we got up close and personal with MNIST. \n",
        "* We got some code to import MNIST data and reshape it to X and Y matrices fit for our binary classification code. \n",
        "* In the end, we used our program to recognize one of the digits in MNIST, with very encouraging results.\n",
        "* Along the way, you learned a few interesting facts about image recognition.\n",
        "* You also learned something about testing ML systems, and how the results of a test can be tricky to interpret because of overfitting.\n",
        "* In the next part, we’ll finally tackle the challenge that we set for ourselves on the second class: recognizing arbitrary digits. How will our code fare?\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-5VUj1z2x_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass classification"
      ],
      "metadata": {
        "id": "IitqeNldF_fO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just learned in the slides that we have to build an array of ten probability estimations, one for each digit.\n",
        "\n",
        "For that, we will first encode our $Y$ label using a very popular encoding technique, one-hot encoding.\n",
        "\n",
        "\n",
        "\n",
        "> In digital circuits and machine learning, a one-hot is a group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0)\n",
        "\n"
      ],
      "metadata": {
        "id": "fhCVdJMosAzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot encoding our target variable\n",
        "\n",
        "We are going to encode our $Y$ labels into one big matrix with ten columns, where each column encodes a digit from 0 to 9.\n",
        "\n",
        "Hint: remember the unique function of Numpy.\n",
        "\n",
        "Try to do this by yourself"
      ],
      "metadata": {
        "id": "kiUiEGpHsYls"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H1vxc21E4tLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9eNG2Kki6ZqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b54gUHOJ7X0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJ57VHkFtJ_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_D1GxBSHuYD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4gVMs_XuqHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KM9fmz32u1E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoding the classifier output\n",
        "\n",
        "Let’s review how `predict()` works. During the classification phase, the transformed weighted sum (linear combination + sigmoid given by `forward()` function) returns a soft prediction between 0 to 1 or a hard prediction, either 0 or 1.\n",
        "\n",
        "```python\n",
        "def predict(X, beta, return_proba=False):\n",
        "  if return_proba:\n",
        "    return forward(X,beta)\n",
        "  else:\n",
        "    return np.round(forward(X,beta))\n",
        "```\n",
        "\n",
        "```python\n",
        "def forward(X, beta):\n",
        "  weighted_sum = np.matmul(X, beta)\n",
        "  return sigmoid(weighted_sum)\n",
        "```"
      ],
      "metadata": {
        "id": "0U3KsKR8vr4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to return a vector of 10 probabilities, one for each digit, or a hard prediction, a number between 0 and 9.\n",
        "\n",
        "How can we do that?"
      ],
      "metadata": {
        "id": "BxyouwTLxWgg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wCKAyOf1usiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding more weights (betas)"
      ],
      "metadata": {
        "id": "DL5KekUGyfmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we introduced one-hot encoding, we extended the matrix of labels from\n",
        "one to ten columns. Now we need to do the same with the weights.\n",
        "\n",
        "So far, our matrix of weights had one column, and one row per input variable.\n",
        "We initialized it like this:\n",
        "```python\n",
        "beta = np.zeros((X.shape[1], 1))\n",
        "```\n",
        "Now we need ten columns of weights, one per class:\n",
        "\n",
        "How can we do that?"
      ],
      "metadata": {
        "id": "ZoXne233yfpl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqAGxhP0yewm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, Y, iterations, lr=0.001, precision=1e-6, print_step=1):\n",
        "  #insert the new beta line below\n",
        "\n",
        "  previous_loss = log_loss(X, Y, beta) \n",
        "  for i in range(iterations):\n",
        "    if i % print_step ==0:\n",
        "      print(f'Iteration {i} => Loss(Log-loss): {previous_loss:.10f}')\n",
        "    beta -= gradient(X, Y, beta) * lr\n",
        "\n",
        "    current_loss = log_loss(X, Y, beta)\n",
        "    if (abs(current_loss - previous_loss) < precision):\n",
        "      print(f'Early stop at iteration {i}')\n",
        "      return beta\n",
        "    previous_loss = current_loss\n",
        "\n",
        "  return beta"
      ],
      "metadata": {
        "id": "H-3m8s_Kuuyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VXoSgJMtym4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yiyflE0nys3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cnUUdMICzFOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CGv83UaOzTes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlBdrFLO0DpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lQF-wvbLz1iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7C9r4jMb0EfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary second part\n",
        "\n",
        "Let’s recap our first adventure in machine learning:\n",
        "\n",
        "* At the beginning of the class we learned how Machine Learning Works and what machine learning and supervised learning are.\n",
        "* Then we got our first concrete taste of supervised learning: we used linear regression to predict one variable from another.\n",
        "* After that, we upgraded the learning program with a faster and more efficient algorithm: gradient descent.\n",
        "* In the next step, we took advantage of gradient descent to implement multiple linear regression—like linear regression, only with multiple inputs.\n",
        "* Our next step consisted in moving from multiple linear regression to classification.\n",
        "* Then, we used our binary classifier to recognize a single digit in the MNIST dataset.\n",
        "* Finally, we bumped up to multiclass classification, recognizing all MNIST characters with over 90% accuracy.\n",
        "\n",
        "I hope you have learned a lot during the first 6 weeks of our course.\n"
      ],
      "metadata": {
        "id": "Ru5EAADvQJi-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwvsEvDx0Z01"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}